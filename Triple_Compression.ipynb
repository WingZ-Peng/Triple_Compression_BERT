{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5V8ywO7MC79"
      },
      "source": [
        "### Configure and verify the environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dB_M6rUeY1bV"
      },
      "outputs": [],
      "source": [
        "# uncommand following to install library\n",
        "\n",
        "! pip install transformers\n",
        "! pip install datasets\n",
        "! pip install torch==2.0.1 torchvision==0.15.2\n",
        "! pip install accelerate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLRhVROaVNYk"
      },
      "source": [
        "### Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "s3LQkpnfV8wJ"
      },
      "outputs": [],
      "source": [
        "# import libs\n",
        "import os\n",
        "import re\n",
        "import sys\n",
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import transformers\n",
        "import datasets\n",
        "from datasets import load_dataset, load_metric\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xeAD_tCTY1bW"
      },
      "outputs": [],
      "source": [
        "task = 'mnli'\n",
        "# task = 'mnli-mm'\n",
        "\n",
        "dataset = load_dataset(\"glue\", task)\n",
        "metric = load_metric(\"glue\", task)\n",
        "\n",
        "# before feed texts to model, need to prepocessing data, it can be done by Transformer Tokenizer\n",
        "batch_size = 16\n",
        "\n",
        "# model type: BERT && DistilBERT\n",
        "# model_checkpoint = \"bert-base-uncased\"\n",
        "model_checkpoint = \"distilbert-base-uncased\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)\n",
        "\n",
        "task_to_keys = {\"mnli\": (\"premise\", \"hypothesis\")}\n",
        "sentence1_key, sentence2_key = task_to_keys[task]\n",
        "\n",
        "def preprocess_function(samples):\n",
        "  return tokenizer(samples[sentence1_key], samples[sentence2_key], truncation=True)\n",
        "\n",
        "# use one single command to preprocess train, validation and test data\n",
        "encoded_dataset = dataset.map(preprocess_function, batched=True)\n",
        "\n",
        "# MNLI has 3 labels\n",
        "num_labels = 3\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=num_labels)\n",
        "metric_name = 'accuracy'\n",
        "model_name = model_checkpoint.split(\"/\")[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "DSidQQK_Y1bW"
      },
      "outputs": [],
      "source": [
        "# Trainer configuration\n",
        "args = TrainingArguments(\n",
        "    f\"{model_name}_output\",\n",
        "    evaluation_strategy = \"epoch\",\n",
        "    save_strategy = \"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=1,\n",
        "    weight_decay=0.01,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=metric_name\n",
        ")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "\n",
        "    return metric.compute(predictions=predictions, references=labels)\n",
        "\n",
        "validation_key = \"validation_mismatched\" if task == \"mnli-mm\" else \"validation_matched\"\n",
        "\n",
        "trainer = Trainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=encoded_dataset[\"train\"],\n",
        "    eval_dataset=encoded_dataset[validation_key],\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h9u7uq_IY1bW"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "clg73G4gY1bW"
      },
      "outputs": [],
      "source": [
        "# Output two models size\n",
        "def print_size_of_model(model):\n",
        "    torch.save(model.state_dict(), \"temp.p\")\n",
        "    print('Size (MB):', os.path.getsize(\"temp.p\")/1e6)\n",
        "    os.remove('temp.p')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "qBYKkpQMY1bW"
      },
      "outputs": [],
      "source": [
        "# define a evaluation function\n",
        "def evaluate(model, encoded_dataset, mnli_dataset, test_dataset):\n",
        "  matched = 0\n",
        "  N = len(encoded_dataset)\n",
        "  print(f'Total matched samples: {N}')\n",
        "\n",
        "  '''\n",
        "  corresponding encoded number\n",
        "  netural => 1\n",
        "  contradiction => 2\n",
        "  entailment => 0\n",
        "  '''\n",
        "  for i, batches in enumerate(encoded_dataset):\n",
        "    premise = batches['premise']\n",
        "    hypothesis = batches['hypothesis']\n",
        "    idx = batches['idx']\n",
        "    label = mnli_dataset[idx]['label']\n",
        "    # input to model and predict the label\n",
        "    encode_input = tokenizer(premise, hypothesis, return_tensors='pt')\n",
        "    output = model(**encode_input)\n",
        "    # need Tensor.cpu() to copy the tensor to host memory first\n",
        "    pred = np.argmax(output.logits.detach().cpu().numpy(), axis=1)\n",
        "\n",
        "    if test_dataset:\n",
        "      # all the labels in test_dataset is contradiction\n",
        "      if pred[0] == 2:\n",
        "        matched += 1\n",
        "      # the label of contradiction is -1 in test_dataset\n",
        "      if label != -1:\n",
        "        print('exception in test dataset')\n",
        "    elif pred[0] == label:\n",
        "      matched += 1\n",
        "\n",
        "    if i != 0 and i % 500 == 0:\n",
        "      print(f'Step at: {i / 500}, accu: {matched / N }, matched {matched} out of {i}')\n",
        "\n",
        "  return matched / N"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "6bLF3OwtY1bX"
      },
      "outputs": [],
      "source": [
        "def time_model_evaluation(model, encoded_dataset, mnli_dataset, test_dataset):\n",
        "  eval_start_time = time.time()\n",
        "  acc = evaluate(model, encoded_dataset, mnli_dataset, test_dataset)\n",
        "  eval_end_time = time.time()\n",
        "  eval_duration_time = eval_end_time - eval_start_time\n",
        "  print(\"\\nEND INFO:\")\n",
        "  print(\"Evaluate total time (seconds): {0:.1f}\".format(eval_duration_time))\n",
        "  print(f'Evaluate end accuracy is {acc}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FkONwsa0Y1bX",
        "outputId": "153b0eb9-d790-4d68-b90b-66bdfb0f36e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size (MB): 267.857267\n"
          ]
        }
      ],
      "source": [
        "# size of initial model\n",
        "print_size_of_model(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qVSsIcOYY1bX"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cpu')\n",
        "model.to(device)\n",
        "acc = time_model_evaluation(model, encoded_dataset['validation_matched'], dataset[\"validation_matched\"], test_dataset=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIHCLY9LZ2wj"
      },
      "source": [
        "### PrunBERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "xPK4ygC9anPQ"
      },
      "outputs": [],
      "source": [
        "# encoder_layers_to_keep = ['0', '1', '2', '3', '4', '5']\n",
        "encoder_layers_to_keep = ['0', '1', '2', '4']\n",
        "\n",
        "def prune_state_dict(state_dict):\n",
        "    def create_pruning_pass(layers_to_keep, layer_name):\n",
        "        keep_layers = sorted(\n",
        "            [int(layer_string) for layer_string in layers_to_keep]\n",
        "        )\n",
        "        mapping_dict = {}\n",
        "        for i in range(len(keep_layers)):\n",
        "            mapping_dict[str(keep_layers[i])] = str(i)\n",
        "\n",
        "        regex = re.compile(\"^{layer}.*\\.layers\\.(\\d+)\".format(layer=layer_name))\n",
        "        return {\"substitution_regex\": regex, \"mapping_dict\": mapping_dict}\n",
        "\n",
        "    pruning_passes = []\n",
        "    if encoder_layers_to_keep:\n",
        "        pruning_passes.append(create_pruning_pass(encoder_layers_to_keep, \"encoder\"))\n",
        "\n",
        "    new_state_dict = {}\n",
        "    for layer_name in state_dict.keys():\n",
        "        match = re.search(\"\\.layer\\.(\\d+)\\.\", layer_name)\n",
        "        # if layer has no number in it, it is a supporting layer, such as an\n",
        "        # embedding\n",
        "        if not match:\n",
        "            # print(f'keeps layer name = {layer_name}.')\n",
        "            new_state_dict[layer_name] = state_dict[layer_name]\n",
        "            continue\n",
        "\n",
        "        # otherwise, layer should be pruned.\n",
        "        original_layer_number = match.group(1)\n",
        "\n",
        "        # figure out which mapping dict to replace from\n",
        "        for pruning_pass in pruning_passes:\n",
        "            if original_layer_number in pruning_pass[\"mapping_dict\"]:\n",
        "                new_layer_number = pruning_pass[\"mapping_dict\"][original_layer_number]\n",
        "                idx = layer_name.find(str(original_layer_number))\n",
        "                new_state_key = (\n",
        "                    layer_name[: idx]\n",
        "                    + new_layer_number\n",
        "                    + layer_name[idx + 1 :]\n",
        "                )\n",
        "                # print(f'original layer name = {layer_name}.           , original_layer_number = {original_layer_number}')\n",
        "                # print(f'new layer name      = {new_state_key}         , new_layer_number =  {new_layer_number}')\n",
        "                new_state_dict[new_state_key] = state_dict[layer_name]\n",
        "\n",
        "    return new_state_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "jKi6XGzzaseU"
      },
      "outputs": [],
      "source": [
        "def load_state_dict(state_dict, strict=True):\n",
        "  new_state_dict = prune_state_dict(state_dict)\n",
        "  return new_state_dict\n",
        "\n",
        "pruned_state_dict = load_state_dict(model.state_dict())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQbj7Yx2Y1bX",
        "outputId": "5dd5afdf-2f23-4357-941b-606be8304111"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "pruned_model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=num_labels, num_hidden_layers=len(encoder_layers_to_keep))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ap836AY2Y1bY",
        "outputId": "9ec84600-6678-48d4-a437-98c408fc9962"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# load pre-trained weight for pruned_model\n",
        "pruned_model.load_state_dict(pruned_state_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z2e5fURlY1bY"
      },
      "outputs": [],
      "source": [
        "# train prunBERT\n",
        "prunBERT_trainer = Trainer(\n",
        "    pruned_model,\n",
        "    args,\n",
        "    train_dataset=encoded_dataset[\"train\"],\n",
        "    eval_dataset=encoded_dataset[validation_key],\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BnT7mZM0Y1bY"
      },
      "outputs": [],
      "source": [
        "prunBERT_trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j40iMCE6Y1bY",
        "outputId": "a5322496-6e59-4599-ce21-91507d98685d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size (MB): 211.142703\n"
          ]
        }
      ],
      "source": [
        "print_size_of_model(pruned_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "694p9QKzY1bY"
      },
      "outputs": [],
      "source": [
        "pruned_model.to(device)\n",
        "acc = time_model_evaluation(pruned_model, encoded_dataset['validation_matched'], dataset[\"validation_matched\"], test_dataset=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqbLE3mAdjF9"
      },
      "source": [
        "### Quantization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "LISbx8zsdmd5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6ef3489-8bff-4667-c5fa-88388fab061b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size (MB): 141.064867\n",
            "Size (MB): 54.374213\n"
          ]
        }
      ],
      "source": [
        "# quantization\n",
        "import torch.nn as nn\n",
        "import torch.quantization as quantization\n",
        "import torch.ao.nn.quantized as nnq\n",
        "import copy\n",
        "\n",
        "device = torch.device('cpu')\n",
        "model.to(device)\n",
        "model_quant = copy.deepcopy(pruned_model)\n",
        "\n",
        "#quantization of the Embedding layer\n",
        "original_weights = model_quant.distilbert.embeddings.word_embeddings.weight.clone()\n",
        "embedding_fp32 = nn.Embedding.from_pretrained(original_weights)\n",
        "qconfig = quantization.float_qparams_weight_only_qconfig\n",
        "embedding_fp32.qconfig = qconfig\n",
        "embedding_quantized = nnq.Embedding.from_float(embedding_fp32)\n",
        "\n",
        "model_quant.distilbert.embeddings.word_embeddings = embedding_quantized\n",
        "\n",
        "#dynamic quantization on the Linear layer\n",
        "quantized_model = torch.quantization.quantize_dynamic(\n",
        "    model, {torch.nn.Linear}, dtype=torch.qint8\n",
        ")\n",
        "\n",
        "triple_model = torch.quantization.quantize_dynamic(\n",
        "    model_quant, {torch.nn.Linear}, dtype=torch.qint8\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEOZa0-KY1bY",
        "outputId": "3cabfc2c-ec24-4f83-b8ed-3b9ad6acfb3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size (MB): 138.707319\n",
            "Size (MB): 54.374213\n"
          ]
        }
      ],
      "source": [
        "print_size_of_model(quantized_model)\n",
        "print_size_of_model(triple_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DjfpLIJSY1bY"
      },
      "outputs": [],
      "source": [
        "quantized_model.to(device)\n",
        "acc = time_model_evaluation(quantized_model, encoded_dataset['validation_matched'], dataset[\"validation_matched\"], test_dataset=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CdR-KzZ5Y1bY"
      },
      "outputs": [],
      "source": [
        "triple_model.to(device)\n",
        "acc = time_model_evaluation(triple_model, encoded_dataset['validation_matched'], dataset[\"validation_matched\"], test_dataset=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}